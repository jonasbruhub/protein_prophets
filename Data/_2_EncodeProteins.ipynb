{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\DeepLearningProject\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import esm\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\envs\\DeepLearningProject\\lib\\site-packages\\esm\\pretrained.py:216: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  \"Regression weights not found, predicting contacts will not produce correct results.\"\n"
     ]
    }
   ],
   "source": [
    "model_esm_if1, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
    "model_esm_if1 = model_esm_if1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PretrainedEncoder(proteinID):\n",
    "  fpath = 'C:/Users/jonas/OneDrive/Skrivebord/Deep Learning Project/Data/AlphaFoldDB/' + proteinID + '.pdb' # .pdb format is also acceptable\n",
    "  chain_ids = ['A']\n",
    "  structure = esm.inverse_folding.util.load_structure(fpath, chain_ids)\n",
    "\n",
    "  coords, _ = esm.inverse_folding.multichain_util.extract_coords_from_complex(structure)\n",
    "\n",
    "  target_chain_id = 'A'     # Always use chain \"A\", as we only have 1 protein (chain)\n",
    "  rep = esm.inverse_folding.multichain_util.get_encoder_output_for_complex(model_esm_if1, alphabet, coords, target_chain_id)\n",
    "  return rep.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0168,  0.1001, -0.2247,  ...,  0.4565,  0.1462, -0.4621],\n",
       "        [-1.4382, -0.7791, -0.8029,  ...,  0.3053,  0.0196,  0.1065],\n",
       "        [-1.3222, -0.6228, -0.8992,  ...,  0.2575, -0.0287,  0.0280],\n",
       "        ...,\n",
       "        [ 0.1674,  0.8543, -0.0596,  ..., -0.2779, -0.1158, -0.2841],\n",
       "        [ 0.6398,  0.0417,  0.3769,  ...,  0.2122, -0.2094, -0.3391],\n",
       "        [ 1.0579, -0.1103,  0.7357,  ...,  0.2159,  0.3422,  0.1547]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PretrainedEncoder(\"P10384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was created from google colab\n",
    "with open('ProteinsUsed.txt', 'rb') as fp:\n",
    "    ProteinIDs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EncodedProteins = []\n",
    "# with open('C:/Users/jonas/OneDrive/Skrivebord/Deep Learning Project/EncodedProteins.txt', 'wb') as fp:\n",
    "#     pickle.dump(EncodedProteins,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3432"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('C:/Users/jonas/OneDrive/Skrivebord/Deep Learning Project/Data/EncodedProteins.txt', 'rb') as fp:\n",
    "    EncodedProteins = pickle.load(fp)\n",
    "\n",
    "EncodedProteins.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3432/3432 [11:47:01<00:00, 12.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "for proteinID in tqdm(ProteinIDs):\n",
    "    if not proteinID in EncodedProteins:\n",
    "        encoded = PretrainedEncoder(proteinID)\n",
    "        torch.save(encoded,\"C:/Users/jonas/OneDrive/Skrivebord/Deep Learning Project/Data/AlphaFoldDBEncoded/\" + proteinID + \".pt\")\n",
    "        EncodedProteins += [proteinID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress of encoded proteins\n",
    "with open('C:/Users/jonas/OneDrive/Skrivebord/Deep Learning Project/Data/EncodedProteins.txt', 'wb') as fp:\n",
    "    pickle.dump(EncodedProteins,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
